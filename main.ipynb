{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "pd.set_option('display.max_columns',200,'display.max_rows',300, 'display.max_colwidth',None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding size for nn embedding\n",
    "embedding_size=32\n",
    "\n",
    "# batch size for BERT\n",
    "batch_size=8\n",
    "\n",
    "# movie category embedding size\n",
    "category_embedding_size = 8\n",
    "\n",
    "# transformer chunk size\n",
    "chunk_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>category</th>\n",
       "      <th>year</th>\n",
       "      <th>original_name</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>1995</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1995</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1995</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1995</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                   Movie_name                      category  year  \\\n",
       "0         1                    Toy Story   Animation|Children's|Comedy  1995   \n",
       "1         2                      Jumanji  Adventure|Children's|Fantasy  1995   \n",
       "2         3             Grumpier Old Men                Comedy|Romance  1995   \n",
       "3         4            Waiting to Exhale                  Comedy|Drama  1995   \n",
       "4         5  Father of the Bride Part II                        Comedy  1995   \n",
       "\n",
       "  original_name  Action  Adventure  Animation  Children's  Comedy  Crime  \\\n",
       "0           nan       0          0          1           1       1      0   \n",
       "1           nan       0          1          0           1       0      0   \n",
       "2           nan       0          0          0           0       1      0   \n",
       "3           nan       0          0          0           0       1      0   \n",
       "4           nan       0          0          0           0       1      0   \n",
       "\n",
       "   Documentary  Drama  Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  \\\n",
       "0            0      0        0          0       0        0        0        0   \n",
       "1            0      0        1          0       0        0        0        0   \n",
       "2            0      0        0          0       0        0        0        1   \n",
       "3            0      1        0          0       0        0        0        0   \n",
       "4            0      0        0          0       0        0        0        0   \n",
       "\n",
       "   Sci-Fi  Thriller  War  Western  \n",
       "0       0         0    0        0  \n",
       "1       0         0    0        0  \n",
       "2       0         0    0        0  \n",
       "3       0         0    0        0  \n",
       "4       0         0    0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movies table\n",
    "raw_movies_info_df=pd.read_csv('../interview_recsys_by_Zhouzi_Hu/data/ml-1m/movies.dat',\\\n",
    "                               sep='\\t',\\\n",
    "                               names=[\"movie_info\"],\\\n",
    "                               encoding='latin-1'\\\n",
    "                            )\n",
    "\n",
    "\n",
    "for index,row in raw_movies_info_df.iterrows():\n",
    "    l=row[\"movie_info\"].split('::')\n",
    "    res_l=list(filter(None,l))\n",
    "    raw_title=res_l[1]\n",
    "    title=re.sub(r'\\([^)]*\\)', '',res_l[1])\n",
    "    title=title.split(', ')\n",
    "    reversed_title=title[::-1]\n",
    "    raw_movies_info_df.at[index,'movie_id']=res_l[0]  \n",
    "    raw_movies_info_df.at[index,'Movie_name']=' '.join(reversed_title)\n",
    "    raw_movies_info_df.at[index,'category']=res_l[2]\n",
    "\n",
    "raw_movies_info_df['year']=raw_movies_info_df[\"movie_info\"].str.extract(r'\\((\\d+)\\)')\n",
    "raw_movies_info_df['original_name']=raw_movies_info_df[\"movie_info\"].str.extract(r'\\((?![0-9]+\\))([^)]+)\\)')\n",
    "movies_info_df=raw_movies_info_df[['movie_id','Movie_name','category','year','original_name']]\n",
    "movies_info_df = movies_info_df.astype(str).applymap(lambda x: x.strip())\n",
    "movies_info_df = movies_info_df.astype(str).applymap(lambda x: x.replace(\"\\\\n\", \"\"))\n",
    "movies_info_df = movies_info_df.astype(str).applymap(lambda x: x.replace(\"  \", \" \")) \n",
    "movies_info_df['Movie_name']=movies_info_df['Movie_name'].str.replace(\"  \", \" \")\n",
    "movies_info_df[\"movie_id\"] = movies_info_df[\"movie_id\"].apply(int)\n",
    "\n",
    "genres = [\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\"]\n",
    "genres += [\"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\"]\n",
    "genres += [\"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "\n",
    "for genre in genres:\n",
    "    movies_info_df[genre] = movies_info_df[\"category\"].apply(\n",
    "        lambda values: int(genre in values.split(\"|\"))\n",
    "    )\n",
    "\n",
    "movies_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193     5.0\n",
       "1        1       661     3.0\n",
       "2        1       914     3.0\n",
       "3        1      3408     4.0\n",
       "4        1      2355     5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating table \n",
    "ratings=pd.read_csv(\\\n",
    "    '../interview_2_recsys 2/data/ml-1m/ratings.dat',\\\n",
    "    sep='::',\\\n",
    "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
    "    encoding='latin-1'\\\n",
    ")\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
    "\n",
    "del ratings[\"unix_timestamp\"]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>age_1</td>\n",
       "      <td>job_10</td>\n",
       "      <td>zc_48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>age_56</td>\n",
       "      <td>job_16</td>\n",
       "      <td>zc_70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>age_25</td>\n",
       "      <td>job_15</td>\n",
       "      <td>zc_55117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id sex age_group occupation  zip_code\n",
       "0        1   F     age_1     job_10  zc_48067\n",
       "1        2   M    age_56     job_16  zc_70072\n",
       "2        3   M    age_25     job_15  zc_55117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User table\n",
    "users=pd.read_csv(\\\n",
    "    '../interview_2_recsys 2/data/ml-1m/users.dat.txt',\\\n",
    "    sep='::',\\\n",
    "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
    "    encoding='latin-1'\\\n",
    ")\n",
    "\n",
    "users[\"age_group\"] = users[\"age_group\"].apply(lambda x: f\"age_{x}\")\n",
    "users[\"occupation\"] = users[\"occupation\"].apply(lambda x: f\"job_{x}\")\n",
    "users[\"zip_code\"] = users[\"zip_code\"].apply(lambda x: f\"zc_{x}\")\n",
    "\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie meta table\n",
    "raw_movies_meta_df=pd.read_csv('../interview_2_recsys 2/data/ml-1m/movies_metadata.csv')\n",
    "raw_movies_meta_df['Year']=raw_movies_meta_df['release_date'].str.split('-').str.get(0).str.strip()\n",
    "raw_movies_meta_df['title']=raw_movies_meta_df['title'].str.strip()\n",
    "raw_movies_meta_df['overview']=raw_movies_meta_df['overview']\\\n",
    "    .str.strip()\\\n",
    "        .str.replace(\"\\\\n\", \"\")\\\n",
    "            .str.replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Year</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Women Art Revolution</td>\n",
       "      <td>2010</td>\n",
       "      <td>Through intimate interviews, provocative art, and rare, historical film and video footage, this feature documentary reveals how art addressing political consequences of discrimination and violence, the Feminist Art Revolution radically transformed the art and culture of our times.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#1 Cheerleader Camp</td>\n",
       "      <td>2010</td>\n",
       "      <td>A pair of horny college guys get summer jobs at a sexy cheerleader camp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>Inspired by actual events, a group of 12 year old girls face a night of horror when the compulsive addiction of an online social media game turns a moment of cyber bullying into a night of insanity.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title  Year  \\\n",
       "0  !Women Art Revolution  2010   \n",
       "1    #1 Cheerleader Camp  2010   \n",
       "2                #Horror  2015   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                    overview  \n",
       "0  Through intimate interviews, provocative art, and rare, historical film and video footage, this feature documentary reveals how art addressing political consequences of discrimination and violence, the Feminist Art Revolution radically transformed the art and culture of our times.  \n",
       "1                                                                                                                                                                                                                   A pair of horny college guys get summer jobs at a sexy cheerleader camp.  \n",
       "2                                                                                     Inspired by actual events, a group of 12 year old girls face a night of horror when the compulsive addiction of an online social media game turns a moment of cyber bullying into a night of insanity.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouped movies_meta table based on \"Year\" and \"title\"\n",
    "grouped=raw_movies_meta_df.groupby(['title','Year'])['overview'].first().reset_index()\n",
    "grouped.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>original_name</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>nan</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>1995</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>nan</td>\n",
       "      <td>When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id Movie_name  year                      category original_name  \\\n",
       "0         1  Toy Story  1995   Animation|Children's|Comedy           nan   \n",
       "1         2    Jumanji  1995  Adventure|Children's|Fantasy           nan   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                      overview  \n",
       "0                                                                                              Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.  \n",
       "1  When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join meta table with movies.dat for overview info\n",
    "merged=movies_info_df.merge(grouped,left_on=['Movie_name','year'],right_on=['title','Year'],how='left')\\\n",
    "     .merge(grouped,left_on=['original_name','year'],right_on=['title','Year'],how='left'\n",
    ")\n",
    "\n",
    "merged['overview']=np.where(\\\n",
    "    merged['overview_x'].isna(),\\\n",
    "        merged['overview_y'],\\\n",
    "            merged['overview_x']\\\n",
    "                )\n",
    "                \n",
    "movie_df_p1=merged.query('overview.notna()')[\\\n",
    "    ['movie_id','Movie_name','year','category','original_name','overview']\\\n",
    "        ]\n",
    "\n",
    "# there a great portion (700) of movie records from meta table has wrong release year, so gonna need a second concat\n",
    "grouped2=raw_movies_meta_df.groupby('title')['overview'].first().reset_index()\n",
    "movie_df_p2=merged.query('overview.isna()')[['movie_id','Movie_name','year','category','original_name']]\\\n",
    "    .merge(grouped2,left_on='Movie_name',right_on='title',how='left').drop(columns='title')\n",
    "\n",
    "movie_df_r=pd.concat([movie_df_p1,movie_df_p2],ignore_index=True)\n",
    "movie_df_r.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding user&movie interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>age_1</td>\n",
       "      <td>job_10</td>\n",
       "      <td>zc_48067</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>age_56</td>\n",
       "      <td>job_16</td>\n",
       "      <td>zc_70072</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>age_25</td>\n",
       "      <td>job_12</td>\n",
       "      <td>zc_32793</td>\n",
       "      <td>1193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id sex age_group occupation  zip_code  movie_id  rating  year  Action  \\\n",
       "0        1   F     age_1     job_10  zc_48067      1193     5.0  1975       0   \n",
       "1        2   M    age_56     job_16  zc_70072      1193     5.0  1975       0   \n",
       "2       12   M    age_25     job_12  zc_32793      1193     4.0  1975       0   \n",
       "\n",
       "   Adventure  Animation  Children's  Comedy  Crime  Documentary  Drama  \\\n",
       "0          0          0           0       0      0            0      1   \n",
       "1          0          0           0       0      0            0      1   \n",
       "2          0          0           0       0      0            0      1   \n",
       "\n",
       "   Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  \\\n",
       "0        0          0       0        0        0        0       0         0   \n",
       "1        0          0       0        0        0        0       0         0   \n",
       "2        0          0       0        0        0        0       0         0   \n",
       "\n",
       "   War  Western  year_index  \n",
       "0    0        0          55  \n",
       "1    0        0          55  \n",
       "2    0        0          55  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge user ratings with user information\n",
    "user_ratings_with_info_df=pd.merge(users, ratings, on='user_id')\n",
    "user_ratings_with_info_df=user_ratings_with_info_df.merge(\\\n",
    "    movies_info_df[['movie_id', 'year', 'Action',\n",
    "       'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime',\n",
    "       'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
    "       'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']],on='movie_id')\n",
    "user_ratings_with_info_df['year']=user_ratings_with_info_df['year'].apply(int)\n",
    "\n",
    "\n",
    "# Unique years and create a dictionary to map them to indices\n",
    "unique_years = user_ratings_with_info_df['year'].sort_values().unique()\n",
    "year_to_index = {year: index for index, year in enumerate(unique_years)}\n",
    "\n",
    "# Map 'year' to indices\n",
    "user_ratings_with_info_df['year_index'] = user_ratings_with_info_df['year'].map(year_to_index)\n",
    "user_ratings_with_info_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map user IDs to their corresponding features\n",
    "user_info_dict = users.set_index('user_id')\\\n",
    "    [['age_group', 'occupation', 'sex','zip_code']].\\\n",
    "        to_dict(orient='index'\\\n",
    "                )\n",
    "\n",
    "# Unique user and movie id\n",
    "unique_user_ids = user_ratings_with_info_df['user_id'].unique()\n",
    "unique_movie_ids = user_ratings_with_info_df['movie_id'].unique()\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "user_ids_tensor = torch.tensor(user_ratings_with_info_df['user_id'].values, dtype=torch.long)\n",
    "movie_ids_tensor = torch.tensor(user_ratings_with_info_df['movie_id'].values, dtype=torch.long)\n",
    "ratings_tensor = torch.tensor(user_ratings_with_info_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# User Embedding Layer\n",
    "user_embedding_layer = nn.Embedding(\\\n",
    "    num_embeddings=max(unique_user_ids) + 1, \\\n",
    "        embedding_dim=embedding_size\\\n",
    "            )\n",
    "\n",
    "user_embedded = user_embedding_layer(user_ids_tensor)\n",
    "\n",
    "# Movie Embedding Layer\n",
    "movie_embedding_layer = nn.Embedding(\\\n",
    "    num_embeddings=max(unique_movie_ids) + 1, \\\n",
    "        embedding_dim=embedding_size\\\n",
    "            )\n",
    "\n",
    "movie_embedded = movie_embedding_layer(movie_ids_tensor)\n",
    "\n",
    "# Movie Category Embedding Layer\n",
    "category_columns = [\\\n",
    "    'Action', 'Adventure', 'Animation', 'Children\\'s', \\\n",
    "        'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "                    'Fantasy', 'Film-Noir', 'Horror', 'Musical', \\\n",
    "                        'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\\\n",
    "                            ]\n",
    "\n",
    "movie_categories_tensor = torch.tensor(\\\n",
    "    user_ratings_with_info_df[category_columns].values, \\\n",
    "        dtype=torch.float\\\n",
    "            )\n",
    "\n",
    "num_categories = movie_categories_tensor.shape[1]  \n",
    "movie_category_embedding_layer = nn.Embedding(\\\n",
    "    num_embeddings=2, embedding_dim=category_embedding_size\\\n",
    "        ) \n",
    "\n",
    "category_embeddings = movie_category_embedding_layer(movie_categories_tensor.long())\n",
    "\n",
    "# Aggregate category embeddings for each user\n",
    "user_category_embeddings = category_embeddings.sum(dim=1)\n",
    "\n",
    "# Movie Year Embedding Layer\n",
    "year_tensor = torch.tensor(user_ratings_with_info_df['year_index'].values, dtype=torch.long)\n",
    "year_embedding_layer = nn.Embedding(num_embeddings=len(unique_years), embedding_dim=embedding_size)\n",
    "year_embedding = year_embedding_layer(year_tensor)\n",
    "\n",
    "# Combine user and movie embeddings\n",
    "embedding_input = torch.cat([user_embedded, movie_embedded,user_category_embeddings,year_embedding], dim=1)\n",
    "\n",
    "# Convert categorical features to numeric representations\n",
    "age_tensor = torch.tensor(\\\n",
    "    user_ratings_with_info_df['age_group'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "occupation_tensor = torch.tensor(\\\n",
    "    user_ratings_with_info_df['occupation'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "gender_tensor = torch.tensor(\\\n",
    "    user_ratings_with_info_df['sex'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "zipcode_tensor = torch.tensor(\\\n",
    "    user_ratings_with_info_df['zip_code'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "\n",
    "# Define embedding layers for categorical features\n",
    "embedding_layer_age = nn.Embedding(\\\n",
    "    num_embeddings=user_ratings_with_info_df['age_group'].nunique(), \\\n",
    "        embedding_dim=embedding_size\\\n",
    "            )\n",
    "\n",
    "embedding_layer_occupation = nn.Embedding(\\\n",
    "    num_embeddings=user_ratings_with_info_df['occupation'].nunique(), \\\n",
    "        embedding_dim=embedding_size\\\n",
    "            )\n",
    "\n",
    "embedding_layer_gender = nn.Embedding(\\\n",
    "    num_embeddings=user_ratings_with_info_df['sex'].nunique(), \\\n",
    "        embedding_dim=embedding_size\\\n",
    "            )\n",
    "\n",
    "embedding_layer_zipcode = nn.Embedding(\\\n",
    "    num_embeddings=user_ratings_with_info_df['zip_code'].nunique(), \\\n",
    "        embedding_dim=embedding_size\\\n",
    "            )\n",
    "\n",
    "# Convert categorical features to numeric representations using embedding layers\n",
    "age_embedding = embedding_layer_age(age_tensor)\n",
    "occupation_embedding = embedding_layer_occupation(occupation_tensor)\n",
    "gender_embedding = embedding_layer_gender(gender_tensor)\n",
    "zipcode_embedding = embedding_layer_zipcode(zipcode_tensor)\n",
    "\n",
    "# Concatenate or sum embeddings\n",
    "categorical_embeddings = torch.cat(\\\n",
    "    [age_embedding, occupation_embedding, gender_embedding, zipcode_embedding], \\\n",
    "        dim=1\\\n",
    "            )\n",
    "\n",
    "# Combine with embedding_input\n",
    "combined_input = torch.cat([embedding_input, categorical_embeddings], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chunks:   5%|â–Œ         | 517/10003 [00:12<03:47, 41.77chunk/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m input_chunk \u001b[38;5;241m=\u001b[39m combined_input[start_idx:end_idx]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Pass the chunk through the transformer layer\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m transformer_output_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Aggregate the transformer_output_chunk using sum\u001b[39;00m\n\u001b[0;32m     17\u001b[0m agg_result[start_idx:end_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m transformer_output_chunk\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:206\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    204\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src, mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[0;32m    205\u001b[0m                       is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal)\n\u001b[1;32m--> 206\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:460\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    457\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 460\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:848\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    846\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[0;32m    847\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[1;32m--> 848\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:874\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 874\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunk_size = 100\n",
    "num_chunks = combined_input.size(0) // chunk_size + 1\n",
    "agg_result = torch.zeros_like(combined_input)\n",
    "# Transformer Layer\n",
    "transformer_layer = nn.Transformer(d_model=combined_input.size(1), nhead=2, num_encoder_layers=1)\n",
    "\n",
    "# Process input in chunks\n",
    "for i in tqdm(range(num_chunks), desc=\"Processing Chunks\", unit=\"chunk\"):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = (i + 1) * chunk_size\n",
    "    input_chunk = combined_input[start_idx:end_idx]\n",
    "\n",
    "    # Pass the chunk through the transformer layer\n",
    "    transformer_output_chunk = transformer_layer(input_chunk, input_chunk)\n",
    "\n",
    "    # Aggregate the transformer_output_chunk using sum\n",
    "    agg_result[start_idx:end_idx] += transformer_output_chunk\n",
    "\n",
    "# Calculate the mean of aggregated results\n",
    "final_result = agg_result / num_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3457, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT input df\n",
    "df_set_BERT=movie_df_r.query('overview.notna()')[['movie_id','overview']].reset_index(drop=True)\n",
    "df_set_BERT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 433/433 [00:14<00:00, 30.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name='bert-base-uncased'\n",
    "tokenizer=BertTokenizer.from_pretrained(model_name)\n",
    "model=BertModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "\n",
    "# Tokenize overview col\n",
    "df_set_BERT['tokens_BERT'] = df_set_BERT['overview'].apply(\\\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True)\\\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df_set_BERT['tokens_BERT'] contains the tokenized sequences\n",
    "max_seq_length = df_set_BERT['tokens_BERT'].apply(len).max()\n",
    "\n",
    "# Move tokens to GPU\n",
    "tokens_on_gpu = [torch.tensor(tokens).to('cuda') for tokens in df_set_BERT['tokens_BERT']]\n",
    "\n",
    "# Pad sequences and create padded_tokens tensor on GPU\n",
    "padded_tokens = pad_sequence([\\\n",
    "    torch.cat([tokens, \\\n",
    "        torch.zeros(max_seq_length - len(tokens)).to('cuda')]) for tokens in tokens_on_gpu], \\\n",
    "            batch_first=True\\\n",
    "                )\n",
    "\n",
    "# Convert padded_tokens to Long type\n",
    "padded_tokens = padded_tokens.type(torch.LongTensor).to('cuda')\n",
    "\n",
    "# Create DataLoader for batching\n",
    "data_loader = DataLoader(TensorDataset(padded_tokens), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize an empty list to store hidden states\n",
    "all_hidden_states = []\n",
    "\n",
    "# Process batches\n",
    "with torch.no_grad(),tqdm(total=len(data_loader)) as pbar:\n",
    "    for batch_tokens in data_loader:\n",
    "        # Ensure batch_tokens is a PyTorch tensor\n",
    "        batch_tokens = batch_tokens[0].to('cuda')\n",
    "\n",
    "        outputs = model(batch_tokens)\n",
    "\n",
    "        # Extract all 12 layers of hidden states\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # Get the last 2 layers and take the average along the layer-axis\n",
    "        last_2_layer_hidden_states = torch.mean(hidden_states[-2:], axis=0)\n",
    "\n",
    "        # Mean pooling along the token-axis\n",
    "        sentence_embedding = torch.mean(last_2_layer_hidden_states, axis=1)\n",
    "\n",
    "        # Append the embeddings to the list\n",
    "        all_hidden_states.append(sentence_embedding)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# Concatenate the embeddings\n",
    "df_set_BERT['sentence_embedding'] = torch.cat(all_hidden_states, dim=0)[:len(df_set_BERT)].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3xDense Layers with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BERT embeddings to tensor\n",
    "bert_embeddings = torch.tensor(df_set_BERT['sentence_embedding'].tolist()).to('cuda')\n",
    "\n",
    "# Concatenate BERT embeddings and transformer output\n",
    "combined_features = torch.cat([bert_embeddings, final_result], dim=1)\n",
    "\n",
    "# Define three dense layers with ReLU activation\n",
    "dense_layer1 = nn.Linear(combined_features.size(1), 512)\n",
    "dense_layer2 = nn.Linear(512, 256)\n",
    "dense_layer3 = nn.Linear(256, 1)\n",
    "\n",
    "# Move dense layers to GPU\n",
    "dense_layer1.to('cuda')\n",
    "dense_layer2.to('cuda')\n",
    "dense_layer3.to('cuda')\n",
    "\n",
    "# Pass through dense layers with ReLU\n",
    "output = relu(dense_layer1(combined_features))\n",
    "output = relu(dense_layer2(output))\n",
    "output = dense_layer3(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predicted rating\n",
    "predictions=output.cpu().detach().numpy().flatten()\n",
    "\n",
    "# Define actual rating\n",
    "actual=user_ratings_with_info_df['ratings'].values\n",
    "\n",
    "# Adding to GPU\n",
    "predicted_ratings_tensor = torch.tensor(predictions, dtype=torch.float).to('cuda')\n",
    "actual_ratings_tensor = torch.tensor(actual, dtype=torch.float).to('cuda')\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_loss = nn.MSELoss()(predicted_ratings_tensor, actual_ratings_tensor)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse_loss.item()}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
